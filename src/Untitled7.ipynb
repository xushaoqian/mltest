{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 break\n",
      "(1, 0.4200000000000001)\n",
      "[0.02, 0.0, 0.0, 0.02, 0.0, 0.0]\n",
      "[-0.039999999999999994, -0.12000000000000001]\n",
      "0.58\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "\"\"\"\n",
    "      主要思想及算法流程来自李航的《统计学习方法》\n",
    "      《理解SVM的三重境界》\n",
    "      yi={1,-1}\n",
    "      难点：\n",
    "      KKT条件\n",
    "      SMO算法\n",
    "\"\"\"\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import copy\n",
    "a=np.matrix([[1.2,3.1,3.1]])\n",
    "#print a.astype(int)\n",
    "#print a.A\n",
    "\n",
    "class SVM:\n",
    "      def __init__(self,data,kernel,maxIter,C,epsilon):\n",
    "            self.trainData=data\n",
    "            self.C=C  #惩罚因子\n",
    "            self.kernel=kernel\n",
    "            self.maxIter=maxIter\n",
    "            self.epsilon=epsilon\n",
    "            self.a=[0 for i in range(len(self.trainData))]\n",
    "            self.w=[0 for i in range(len(self.trainData[0][0]))]\n",
    "            self.eCache=[[0,0] for i in range(len(self.trainData))]\n",
    "            self.b=0\n",
    "            self.xL=[self.trainData[i][0] for i in range(len(self.trainData))]\n",
    "            self.yL=[self.trainData[i][1] for i in range(len(self.trainData))]\n",
    "\n",
    "      def train(self):\n",
    "            #support_Vector=self.__SMO()\n",
    "            self.__SMO()\n",
    "            self.__update()\n",
    "\n",
    "      def __kernel(self,A,B):\n",
    "            #核函数 是对输入的向量进行变形 从低维映射到高维度\n",
    "            res=0\n",
    "            if self.kernel=='Line':\n",
    "                  res=self.__Tdot(A,B)\n",
    "            elif self.kernel[0]=='Gauss':\n",
    "                  K=0\n",
    "                  for m in range(len(A)):\n",
    "                       K+=(A[m]-B[m])**2 \n",
    "                  res=math.exp(-0.5*K/(self.kernel[1]**2))\n",
    "            return res\n",
    "\n",
    "\n",
    "      def __Tdot(self,A,B):\n",
    "            res=0\n",
    "            for k in range(len(A)):\n",
    "                  res+=A[k]*B[k]\n",
    "            return res\n",
    "\n",
    "\n",
    "      def __SMO(self):\n",
    "            #SMO是基于 KKT 条件的迭代求解最优化问题算法\n",
    "            #SMO是SVM的核心算法\n",
    "            support_Vector=[]\n",
    "            self.a=[0 for i in range(len(self.trainData))]\n",
    "            pre_a=copy.deepcopy(self.a)\n",
    "            for it in range(self.maxIter):\n",
    "                  flag=1\n",
    "                  for i in range(len(self.xL)):\n",
    "                        #print self.a\n",
    "                        #更新 self.a  使用 机器学习实战的求解思路\n",
    "                        #计算 j更新\n",
    "                        diff=0\n",
    "                        self.__update()\n",
    "                        #选择有最大误差的j 丹麦理工大学的算法是 对j在数据集上循环, 随机选取i 显然效率不是很高\n",
    "                        #机器学习实战 硬币书表述正常 代码混乱且有错误 启发式搜索\n",
    "                        Ei=self.__calE(self.xL[i],self.yL[i])\n",
    "                        j,Ej=self.__chooseJ(i,Ei)\n",
    "                        #计算 L H\n",
    "                        (L,H)=self.__calLH(pre_a,j,i)\n",
    "                        #思路是先表示为self.a[j] 的唯一变量的函数 再进行求导（一阶导数=0 更新）\n",
    "                        kij=self.__kernel(self.xL[i],self.xL[i])+self.__kernel(self.xL[j],self.xL[j])-2*self.__kernel(self.xL[i],self.xL[j])\n",
    "                        #print kij,\"aa\"\n",
    "                        if(kij==0):\n",
    "                              continue\n",
    "                        self.a[j] = pre_a[j] + float(1.0*self.yL[j]*(Ei-Ej))/kij\n",
    "                        #下届是L 也就是截距,小于0时为0\n",
    "                        #上届是H 也就是最大值,大于H时为H\n",
    "                        self.a[j] = min(self.a[j], H)\n",
    "                        self.a[j] = max(self.a[j], L)\n",
    "                        #self.a[j] = min(self.a[j], H)\n",
    "                        #print L,H\n",
    "                        self.eCache[j]=[1,self.__calE(self.xL[j],self.yL[j])]\n",
    "                        self.a[i] = pre_a[i]+self.yL[i]*self.yL[j]*(pre_a[j]-self.a[j])\n",
    "                        self.eCache[i]=[1,self.__calE(self.xL[i],self.yL[i])]\n",
    "                        diff=sum([abs(pre_a[m]-self.a[m]) for m in range(len(self.a))])\n",
    "                        #print diff,pre_a,self.a\n",
    "                        if diff < self.epsilon:\n",
    "                              flag=0\n",
    "                        pre_a=copy.deepcopy(self.a)\n",
    "                  if flag==0:\n",
    "                        print it,\"break\"\n",
    "                        break\n",
    "\n",
    "            #return support_Vector\n",
    "\n",
    "      def __chooseJ(self,i,Ei):\n",
    "            self.eCache[i]=[1,Ei]\n",
    "            chooseList=[]\n",
    "            #print self.eCache\n",
    "            #从误差缓存中得到备选的j的列表 chooseList  误差缓存的作用：解决初始选择问题\n",
    "            for p in range(len(self.eCache)):\n",
    "                  if self.eCache[p][0]!=0 and p!=i:\n",
    "                        chooseList.append(p)\n",
    "            if len(chooseList)>1:\n",
    "                  delta_E=0\n",
    "                  maxE=0\n",
    "                  j=0\n",
    "                  Ej=0\n",
    "                  for k in chooseList:\n",
    "                        Ek=self.__calE(self.xL[k],self.yL[k])\n",
    "                        delta_E=abs(Ek-Ei)\n",
    "                        if delta_E>maxE:\n",
    "                              maxE=delta_E\n",
    "                              j=k\n",
    "                              Ej=Ek\n",
    "                  return j,Ej\n",
    "            else:\n",
    "                  #最初始状态\n",
    "                  j=self.__randJ(i)\n",
    "                  Ej=self.__calE(self.xL[j],self.yL[j])\n",
    "                  return j,Ej\n",
    "\n",
    "      def __randJ(self,i):\n",
    "            j=i\n",
    "            while(j==i):\n",
    "                  j=random.randint(0,len(self.xL)-1)\n",
    "            return j\n",
    "\n",
    "      def __calLH(self,pre_a,j,i):\n",
    "            if(self.yL[j]!= self.yL[i]):\n",
    "                  return (max(0,pre_a[j]-pre_a[i]),min(self.C,self.C-pre_a[i]+pre_a[j]))\n",
    "            else:\n",
    "                  return (max(0,-self.C+pre_a[i]+pre_a[j]),min(self.C,pre_a[i]+pre_a[j]))\n",
    "\n",
    "      def __calE(self,x,y):\n",
    "            #print x,y\n",
    "            y_,q=self.predict(x)\n",
    "            return y_-y\n",
    "\n",
    "      def __calW(self):\n",
    "            self.w=[0 for i in range(len(self.trainData[0][0]))]\n",
    "            for i in range(len(self.trainData)):\n",
    "                  for j in range(len(self.w)):\n",
    "                        self.w[j]+=self.a[i]*self.yL[i]*self.xL[i][j]\n",
    "\n",
    "      def __update(self):\n",
    "            #更新 self.b 和 self.w\n",
    "            self.__calW()\n",
    "            #得到了self.w 下面求b\n",
    "            #print self.a\n",
    "            maxf1=-99999\n",
    "            min1=99999\n",
    "            for k in range(len(self.trainData)):\n",
    "                  y_v=self.__Tdot(self.w,self.xL[k])\n",
    "                  #print y_v\n",
    "                  if self.yL[k]==-1:\n",
    "                        if y_v>maxf1:\n",
    "                              maxf1=y_v\n",
    "                  else:\n",
    "                        if y_v<min1:\n",
    "                              min1=y_v\n",
    "            self.b=-0.5*(maxf1+min1)\n",
    "\n",
    "      def predict(self,testData):\n",
    "            pre_value=0\n",
    "            #从trainData 改成 suport_Vector\n",
    "            for i in range(len(self.trainData)):\n",
    "                  pre_value+=self.a[i]*self.yL[i]*self.__kernel(self.xL[i],testData)\n",
    "            pre_value+=self.b\n",
    "            #print pre_value,\"pre_value\"\n",
    "            if pre_value<0:\n",
    "                  y=-1\n",
    "            else:\n",
    "                  y=1\n",
    "            return y,abs(pre_value-0)\n",
    "\n",
    "      def save(self):\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def LoadSVM():\n",
    "      pass\n",
    "    \n",
    "data=[\n",
    "        [[1,1],1],\n",
    "        [[2,1],1],\n",
    "        [[1,0],1],\n",
    "        [[3,7],-1],\n",
    "        [[4,8],-1],\n",
    "        [[4,10],-1],\n",
    "      ]\n",
    "\n",
    "svm=SVM(data,'Line',1000,0.02,0.001)\n",
    "svm.train()\n",
    "print svm.predict([4,0])\n",
    "print svm.a\n",
    "print svm.w\n",
    "print svm.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named SVM",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-a18624a52e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mSVM\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m data=[\n\u001b[1;32m      5\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named SVM"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "from SVM import *\n",
    "\n",
    "data=[\n",
    "        [[1,1],1],\n",
    "        [[2,1],1],\n",
    "        [[1,0],1],\n",
    "        [[3,7],-1],\n",
    "        [[4,8],-1],\n",
    "        [[4,10],-1],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0daf1cc0a16f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#如果为gauss核的话  ['Gauss',标准差]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msvm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSVM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Line'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "#如果为gauss核的话  ['Gauss',标准差]\n",
    "svm=SVM(data,'Line',1000,0.02,0.001)\n",
    "svm.train()\n",
    "print svm.predict([4,0])\n",
    "print svm.a\n",
    "print svm.w\n",
    "print svm.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
